<!doctype html><html lang=en><head><title>Go sync.Pool contention Â· isopov
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Ivan Sopov"><meta name=description content="Recently my colleague suggested that contention on a single sync.Pool in Go may hit performance. I decided to reproduce this performance hit in a benchmark. This is what I was capable of writing.
import ( &#34;runtime&#34; &#34;strconv&#34; &#34;sync&#34; &#34;sync/atomic&#34; &#34;testing&#34; ) func workWithPool(pool *sync.Pool) { const size = 1000 values := [size]int{} for i := 0; i < size; i++ { values[i] = pool.Get().(int) } for i := 0; i < size; i++ { pool."><meta name=keywords content="blog,developer,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Go sync.Pool contention"><meta name=twitter:description content="Recently my colleague suggested that contention on a single sync.Pool in Go may hit performance. I decided to reproduce this performance hit in a benchmark. This is what I was capable of writing.
import ( &#34;runtime&#34; &#34;strconv&#34; &#34;sync&#34; &#34;sync/atomic&#34; &#34;testing&#34; ) func workWithPool(pool *sync.Pool) { const size = 1000 values := [size]int{} for i := 0; i < size; i++ { values[i] = pool.Get().(int) } for i := 0; i < size; i++ { pool."><meta property="og:title" content="Go sync.Pool contention"><meta property="og:description" content="Recently my colleague suggested that contention on a single sync.Pool in Go may hit performance. I decided to reproduce this performance hit in a benchmark. This is what I was capable of writing.
import ( &#34;runtime&#34; &#34;strconv&#34; &#34;sync&#34; &#34;sync/atomic&#34; &#34;testing&#34; ) func workWithPool(pool *sync.Pool) { const size = 1000 values := [size]int{} for i := 0; i < size; i++ { values[i] = pool.Get().(int) } for i := 0; i < size; i++ { pool."><meta property="og:type" content="article"><meta property="og:url" content="https://isopov.github.io/posts/sync-pool-contention/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-03-24T16:22:39+03:00"><meta property="article:modified_time" content="2023-03-24T16:22:39+03:00"><link rel=canonical href=https://isopov.github.io/posts/sync-pool-contention/><link rel=preload href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.135e22c97ff685fe983fc60048e309ced8f00d8d38f536aa67dba8a13a03dfa4.css integrity="sha256-E14iyX/2hf6YP8YASOMJztjwDY049TaqZ9uooToD36Q=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=icon type=image/svg+xml href=/images/favicon.svg sizes=any><link rel=icon type=image/png href=/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/images/favicon-16x16.png sizes=16x16><link rel=apple-touch-icon href=/images/apple-touch-icon.png><link rel=apple-touch-icon sizes=180x180 href=/images/apple-touch-icon.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/images/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=/>isopov
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/about/>About</a></li><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=/tags/>Tags</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://isopov.github.io/posts/sync-pool-contention/>Go sync.Pool contention</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa fa-calendar" aria-hidden=true></i>
<time datetime=2023-03-24T16:22:39+03:00>March 24, 2023
</time></span><span class=reading-time><i class="fa fa-clock-o" aria-hidden=true></i>
2-minute read</span></div><div class=tags><i class="fa fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/golang/>Golang</a></span></div></div></header><div class=post-content><p>Recently my colleague suggested that contention on a single sync.Pool in Go may hit performance. I decided to reproduce this performance hit in a benchmark. This is what I was capable of writing.</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#fff;font-weight:700>import</span> (
</span></span><span style=display:flex><span>	<span style=color:#0ff;font-weight:700>&#34;runtime&#34;</span>
</span></span><span style=display:flex><span>	<span style=color:#0ff;font-weight:700>&#34;strconv&#34;</span>
</span></span><span style=display:flex><span>	<span style=color:#0ff;font-weight:700>&#34;sync&#34;</span>
</span></span><span style=display:flex><span>	<span style=color:#0ff;font-weight:700>&#34;sync/atomic&#34;</span>
</span></span><span style=display:flex><span>	<span style=color:#0ff;font-weight:700>&#34;testing&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>func</span> workWithPool(pool *sync.Pool) {
</span></span><span style=display:flex><span>	<span style=color:#fff;font-weight:700>const</span> size = <span style=color:#ff0;font-weight:700>1000</span>
</span></span><span style=display:flex><span>	values := [size]<span style=color:#fff;font-weight:700>int</span>{}
</span></span><span style=display:flex><span>	<span style=color:#fff;font-weight:700>for</span> i := <span style=color:#ff0;font-weight:700>0</span>; i &lt; size; i++ {
</span></span><span style=display:flex><span>		values[i] = pool.Get().(<span style=color:#fff;font-weight:700>int</span>)
</span></span><span style=display:flex><span>	}
</span></span><span style=display:flex><span>	<span style=color:#fff;font-weight:700>for</span> i := <span style=color:#ff0;font-weight:700>0</span>; i &lt; size; i++ {
</span></span><span style=display:flex><span>		pool.Put(values[i])
</span></span><span style=display:flex><span>	}
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#fff;font-weight:700>func</span> Benchmark_Pool(b *testing.B) {
</span></span><span style=display:flex><span>	<span style=color:#fff;font-weight:700>for</span> _, parallelism := <span style=color:#fff;font-weight:700>range</span> []<span style=color:#fff;font-weight:700>int</span>{<span style=color:#ff0;font-weight:700>1</span>, <span style=color:#ff0;font-weight:700>2</span>, <span style=color:#ff0;font-weight:700>3</span>, <span style=color:#ff0;font-weight:700>4</span>, <span style=color:#ff0;font-weight:700>5</span>, <span style=color:#ff0;font-weight:700>10</span>, <span style=color:#ff0;font-weight:700>20</span>, <span style=color:#ff0;font-weight:700>50</span>, <span style=color:#ff0;font-weight:700>100</span>} {
</span></span><span style=display:flex><span>		b.Run(<span style=color:#0ff;font-weight:700>&#34;Parallelism &#34;</span>+strconv.Itoa(parallelism), <span style=color:#fff;font-weight:700>func</span>(b *testing.B) {
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>			b.Run(<span style=color:#0ff;font-weight:700>&#34;one pool&#34;</span>, <span style=color:#fff;font-weight:700>func</span>(b *testing.B) {
</span></span><span style=display:flex><span>				b.SetParallelism(parallelism)
</span></span><span style=display:flex><span>				pool := &amp;sync.Pool{
</span></span><span style=display:flex><span>					New: <span style=color:#fff;font-weight:700>func</span>() any {
</span></span><span style=display:flex><span>						<span style=color:#fff;font-weight:700>return</span> <span style=color:#ff0;font-weight:700>42</span>
</span></span><span style=display:flex><span>					},
</span></span><span style=display:flex><span>				}
</span></span><span style=display:flex><span>				b.RunParallel(<span style=color:#fff;font-weight:700>func</span>(pb *testing.PB) {
</span></span><span style=display:flex><span>					<span style=color:#fff;font-weight:700>for</span> pb.Next() {
</span></span><span style=display:flex><span>						workWithPool(pool)
</span></span><span style=display:flex><span>					}
</span></span><span style=display:flex><span>				})
</span></span><span style=display:flex><span>			})
</span></span><span style=display:flex><span>			b.Run(<span style=color:#0ff;font-weight:700>&#34;many pools&#34;</span>, <span style=color:#fff;font-weight:700>func</span>(b *testing.B) {
</span></span><span style=display:flex><span>				b.SetParallelism(parallelism)
</span></span><span style=display:flex><span>				numPools := runtime.GOMAXPROCS(<span style=color:#ff0;font-weight:700>0</span>) * parallelism
</span></span><span style=display:flex><span>				pools := <span style=color:#fff;font-weight:700>make</span>([]*sync.Pool, numPools)
</span></span><span style=display:flex><span>				<span style=color:#fff;font-weight:700>for</span> i := <span style=color:#ff0;font-weight:700>0</span>; i &lt; numPools; i++ {
</span></span><span style=display:flex><span>					pools[i] = &amp;sync.Pool{
</span></span><span style=display:flex><span>						New: <span style=color:#fff;font-weight:700>func</span>() any {
</span></span><span style=display:flex><span>							<span style=color:#fff;font-weight:700>return</span> <span style=color:#ff0;font-weight:700>42</span>
</span></span><span style=display:flex><span>						},
</span></span><span style=display:flex><span>					}
</span></span><span style=display:flex><span>				}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>				procs := <span style=color:#fff;font-weight:700>uint32</span>(<span style=color:#ff0;font-weight:700>0</span>)
</span></span><span style=display:flex><span>				b.RunParallel(<span style=color:#fff;font-weight:700>func</span>(pb *testing.PB) {
</span></span><span style=display:flex><span>					poolidx := atomic.LoadUint32(&amp;procs)
</span></span><span style=display:flex><span>					<span style=color:#fff;font-weight:700>for</span> {
</span></span><span style=display:flex><span>						<span style=color:#fff;font-weight:700>if</span> atomic.CompareAndSwapUint32(&amp;procs, poolidx, poolidx+<span style=color:#ff0;font-weight:700>1</span>) {
</span></span><span style=display:flex><span>							<span style=color:#fff;font-weight:700>break</span>
</span></span><span style=display:flex><span>						}
</span></span><span style=display:flex><span>						poolidx = atomic.LoadUint32(&amp;procs)
</span></span><span style=display:flex><span>					}
</span></span><span style=display:flex><span>					<span style=color:#fff;font-weight:700>for</span> pb.Next() {
</span></span><span style=display:flex><span>						workWithPool(pools[poolidx])
</span></span><span style=display:flex><span>					}
</span></span><span style=display:flex><span>				})
</span></span><span style=display:flex><span>			})
</span></span><span style=display:flex><span>		})
</span></span><span style=display:flex><span>	}
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>It seems that I need to comment a bit on the parallelism parameter. It stands for number of goroutines per each thread, while number of threads by default is equal to number of CPU cores. In my case I have 10 cores and thus 10 threads.
Here are the results with some omissions and reformatting to simplify reading.</p><div class=highlight><pre tabindex=0 style=color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>Benchmark_Pool/Parallelism_1/one_pool         	  	      4513 ns/op
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_1/many_pools       	  	      2364 ns/op
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_2/one_pool         	  	      3078 ns/op
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_2/many_pools       	  	      2273 ns/op
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_3/one_pool         	  	      3144 ns/op
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_3/many_pools       	  	      2272 ns/op
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_4/one_pool         	  	      2979 ns/op
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_4/many_pools       	  	      2315 ns/op
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_5/one_pool         	  	      3355 ns/op
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_5/many_pools       	  	      2314 ns/op
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_10/one_pool        	  	      4948 ns/op
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_10/many_pools      	  	      2269 ns/op
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_20/one_pool        	  	      6979 ns/op
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_20/many_pools      	  	      2288 ns/op
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_50/one_pool        	  	      8324 ns/op
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_50/many_pools      	  	      2371 ns/op
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_100/one_pool       	  	     10044 ns/op
</span></span><span style=display:flex><span>Benchmark_Pool/Parallelism_100/many_pools     	  	      2295 ns/op
</span></span></code></pre></div><p>It seems that with only 1 goroutine per CPU core this code for some reason suffers from contention more than with 2-5 goroutines. However in order to observe noticeable penalty we need 10+ goroutines per core. Keep in mind also that every operation here invokes Get on sync.Pool 1000 times and Put 1000 times also.</p><p>After writing and running this benchmark I conclude that there is no real danger in contention on sync.Pool and it may be used for really common low-level things.</p></div><footer></footer></article></section></div><footer class=footer><section class=container>Â©
2011 -
2023
Ivan Sopov
Â·
Powered by <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script></body></html>